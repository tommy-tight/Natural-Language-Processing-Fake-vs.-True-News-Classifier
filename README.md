# Fake-vs.-True-News-Classifier
This repository is a model that I built to classify news articles as true or fake

## Data Set
The goal of this project was to build classifiers that would be able to accurately classify news articles as True News or Fake News. The dataset used for this analysis comes from Kaggle and contains two files, “True” with around 21,000 news articles all from Reuters, and “False” with 23,000 articles from non-reputable sources. Both of these datasets contain four columns: the title of the article, text (body of the article), subject (politics, world, other), and the date of publication. These articles were sourced from the beginning of 2016 to the end of 2017, with the 2016 U.S. Presidential Election being a key event during this time period and having an influence on a lot of these articles. The datasets can be found in the `True.csv` and `Fake.csv` files or at this [link](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset/?select=Fake.csv.)

## Classification Models 
The first model I used involved the NRC Emotion Lexicon, which maps words to eight specific emotions (e.g. anger, fear, joy, etc.). NRC provides a detailed emotional profile by allowing me to count words associated with each emotion in a document. To build the emotional classifier, I first compared the emotional distributions of true and fake news articles. Fake news articles showed higher emotional intensity overall, especially in negative emotions such as disgust, surprise, and anger, whereas true news showed stronger associations with trust and positivity. For each article, I counted all the words linked to each NRC emotion and multiplied each count by a weight proportional to that emotion’s correlation with true or fake news. I then summed the weighted emotions into two values: a “positive” score, associated with true news and a “negative” score, associated with fake news. Because fake news is generally more emotional, I scaled the negative score by multiplying by 0.25 to avoid overclassifying articles as fake. The classifier then labeled an article as true if the positive score minus the scaled negative score was greater than 0, and false otherwise. This rule-based model reached 65% accuracy with a balanced confusion matrix. Its ROC curve produced an AUC of 0.71, meaning the model correctly ranks a randomly chosen true article higher than a randomly chosen fake article 71% of the time. Overall, emotional profiling performed fairly well for a rule-based model, suggesting that emotions are a somewhat effective classifier of true and fake news. The emotional rule-based model was created using mainly base python, however, I relied on Pandas for some of the dataframe manipulations and I used Scikit–Learn to calculate the confusion matrix and ROC curve. Additionally, I used NLTK to prepare the corpus and vocabulary. Matplotlib and Seaborn were used to create the visualizations

After building the rule-based classifier, I wanted to see if a learning-based classifier would perform better, so I created a Naive Bayes classifier using the Scikit–Learn package. I created a 75%-25% train-test split and trained the model on the 10,000 top features, and the model achieved an accuracy of ~95%. The model drew out key differences in words that tended to identify fake news, such as people and themes that were the topic of a lot of controversy and drama, like Donald Trump, Hillary Clinton, and Twitter during this time period. Words that were correlated with true news tended to relate to actual events and news-worthy happenings, as opposed to dramatic topics and people. While the model performed very well, I wanted to take an adversarial approach and see if fake news articles could pass as true by removing some of these dramatic buzz words. In order to test if this was possible, I calculated which words were most related to fake news and added them to the stopword list and re-ran the model. I removed up to 1000 words most related to fake news, and the accuracy still only dropped to 92% and the AUC of the ROC curve dropped from 98% to 96%. While the most fake-related words changed to be slightly less dramatic, they were still words like war, president, and race, which are representative of hot-button emotion-inflicting topics. Therefore, I determined the model’s performance to be sufficiently effective at classifying fake news and true news, so that even if fake news writers were to reduce their use of some of these fake-related words, they still would not likely be able to pass as true news. The Naive Bayes model consistently recognized the differences between how fake news and true news articles were written, even after attempting to deceive it. I used the NLTK package to create the corpus, and the stopword list. The Scikit–learn package, specifically the CounterVectorizer and MultinomialNB functions were used to generate the model while Seaborn and Matplotlib were used to generate the visualizations. The emotional rule-based model can be found in `Emotional Rule-Based Classifier.ipynb`, the Naive Bayes Classifier can be found in `Naive Bayes Classifier.ipynb`, and the NRC emotional lexicon can be found in `NRC-Emotion-Lexicon-Wordlevel-v0.92.txt`.
